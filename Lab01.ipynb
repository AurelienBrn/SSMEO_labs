{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSMEO Lab 01 : Image coordinates, distorsion model\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Image measurements\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Objectives:</b> In this section you will familiarize yourlsef with image format, image coordinates and manual measurements on images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Read image, define parameters\n",
    "\n",
    "Set up the path to your image and path where to save measurements later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = '/media/topo/Data/ALS/Vallet/Images/18704.jpg'\n",
    "img = cv2.imread(im_path)\n",
    "\n",
    "out_path = '/media/topo/Data/ALS/Vallet/Images/'\n",
    "\n",
    "measurements = {'x':[], 'y':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Perform manual measurements on the image:\n",
    "\n",
    "Use the provided functions to populate **measurements** dictionnary with manual measurements\n",
    "\n",
    "**click_event** function is handling user interaction with the displayed image and details how to perform such measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, measurements):\n",
    "    '''\n",
    "    On user's double left click : add  measurements (x, y in pixels) to measurements dictionnary\n",
    "    and draw it on the image\n",
    "    '''\n",
    "    buf = 25\n",
    "    #On double left click :\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        #Draw cross at clicked pixel\n",
    "        cv2.line(img, (x,y-buf), (x,y+buf), (50,90,255), 1)\n",
    "        cv2.line(img, (x-buf,y), (x+buf,y), (50,90,255), 1)\n",
    "        cv2.putText(img, f\"{x}, {y}\",(x+5, y-5),cv2.FONT_HERSHEY_SIMPLEX,1,(50,90,255),2)\n",
    "\n",
    "        #Update image\n",
    "        cv2.imshow('Manual measurement', img)\n",
    "        \n",
    "        #Store clicked x and y coordinate into measurement dictionnary\n",
    "        measurements['x'].append(x)\n",
    "        measurements['y'].append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diplay loop on the image :\n",
    "\n",
    "cv2.namedWindow('Manual measurement', cv2.WINDOW_NORMAL)\n",
    "cv2.setMouseCallback('Manual measurement', click_event, measurements)\n",
    "cv2.imshow('Manual measurement', img)\n",
    "cv2.resizeWindow('Manual measurement', 1200,800)\n",
    "\n",
    "while True:\n",
    "    k = cv2.waitKey(100)\n",
    "    if k == 27: # wait for ESC key to exit\n",
    "        cv2.destroyAllWindows()\n",
    "        break        \n",
    "    if cv2.getWindowProperty('Manual measurement',cv2.WND_PROP_VISIBLE) < 1:# wait for window to be closed        \n",
    "        break        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Pay attention to the coordinates in pixels when you do a measurement. Where is the origin of X and Y axis ? How are the axis oriented ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define pixel pixel coordinate conversion function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Define function **sensor2perspective** to project pixel coordinates from sensor to perspective centered frame\n",
    "\n",
    "(b) Define function **perspective2sensor** to project pixel coordinates from perspective to sensor centered frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor2perspective(img, xy):\n",
    "    '''\n",
    "    Project from sensor to perspective coordinate system\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : cv2.image\n",
    "        the image from which take a grid\n",
    "    xy : np.array(Nx2)\n",
    "        the array of measurements to project\n",
    "            \n",
    "    Return\n",
    "    ------\n",
    "    proj_xy : np.array(Nx2)\n",
    "        the reprojected array    \n",
    "    '''\n",
    "    #get image size\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    #convert coordinates\n",
    "    proj_xy = np.empty(xy.shape)\n",
    "    proj_xy[:,0] = xy[:,0] - width/2\n",
    "    proj_xy[:,1] = height/2 - xy[:,1]\n",
    "    \n",
    "    return proj_xy\n",
    "\n",
    "#Define function to project from sensor to perspective coordinate system\n",
    "def perspective2sensor(img, xy):\n",
    "    '''\n",
    "    Project from perspective to sensor coordinate system\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : cv2.image\n",
    "        the image from which take a grid\n",
    "    xy : np.array(Nx2)\n",
    "        the array of measurements to project\n",
    "            \n",
    "    Return\n",
    "    ------\n",
    "    proj_xy : np.array(Nx2)\n",
    "        the reprojected array    \n",
    "    '''\n",
    "    #get image size\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    #convert coordinates\n",
    "    proj_xy = np.empty(xy.shape)\n",
    "    proj_xy[:,0] = xy[:,0] + width/2\n",
    "    proj_xy[:,1] = height/2 - xy[:,1]\n",
    "    \n",
    "    return proj_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Up to now, you used a sensor centered coordinate system :\n",
    "    <ul>\n",
    "    <li>The origin is the top-left corner of the image</li>\n",
    "    <li>X is oriented horizontally →</li>\n",
    "    <li>Y cis oriented downward ↓</li>\n",
    "    </ul> \n",
    "    \n",
    "In the next exercise, to undistort images, we will use a perspective centered coordinate system :\n",
    "    <ul>\n",
    "    <li>The origin is the perspective center of the image (approximated by the image center in this case)</li>\n",
    "    <li>X is oriented horizontally →</li>\n",
    "    <li>Y cis oriented upward ↑</li>\n",
    "    </ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test that you projections are correct :\n",
    "height, width, channels = img.shape\n",
    "\n",
    "sensor_dummy = np.array([[0, 0], [width/2, height/2]])\n",
    "perspect_dummy = np.array([[-width/2, height/2], [0, 0]])\n",
    "assert((sensor_dummy == perspective2sensor(img,perspect_dummy)).all())\n",
    "assert((perspect_dummy == sensor2perspective(img,sensor_dummy)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Save measurements to txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Convert your measurements to perspective centered coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements in sensor coordinates :\n",
      " [[8820 1867]\n",
      " [8303 7553]\n",
      " [4616 5169]\n",
      " [8107 4499]\n",
      " [2385 1083]\n",
      " [1445 5912]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([measurements['x'], measurements['y']]).T\n",
    "print(f\"Measurements in sensor coordinates :\\n {xy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements in perspective coordinates :\n",
      " [[ 3656.  2013.]\n",
      " [ 3139. -3673.]\n",
      " [ -548. -1289.]\n",
      " [ 2943.  -619.]\n",
      " [-2779.  2797.]\n",
      " [-3719. -2032.]]\n"
     ]
    }
   ],
   "source": [
    "xy = sensor2perspective(img,xy)\n",
    "print(f\"Measurements in perspective coordinates :\\n {xy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Save your measurements for latter use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements in sensor coordinates :\n",
      " [[8820 1867]\n",
      " [8303 7553]\n",
      " [4616 5169]\n",
      " [8107 4499]\n",
      " [2385 1083]\n",
      " [1445 5912]]\n",
      "Measurements in perspective coordinates :\n",
      " [[ 3656.  2013.]\n",
      " [ 3139. -3673.]\n",
      " [ -548. -1289.]\n",
      " [ 2943.  -619.]\n",
      " [-2779.  2797.]\n",
      " [-3719. -2032.]]\n",
      "Saving 6 measurements to /media/topo/Data/ALS/Vallet/Images/coord.txt :\n"
     ]
    }
   ],
   "source": [
    "np.savetxt(out_path + 'coord.txt', xy, fmt='%d')\n",
    "print(f\"Saving {xy.shape[0]} measurements to {out_path}coord.txt :\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Modelling camera distorsion\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Objectives:</b> Cameras are not perfect and distorsion due to imperfect mounting and lens distorsion must me corrected to accurately map each pixel. \n",
    "    \n",
    "In this section you will implement a simple distorsion model and visualize its effect on the pixels' position\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Load image\n",
    "\n",
    "#### Load your measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 measurements :\n",
      "[[ 3656.  2013.]\n",
      " [ 3139. -3673.]\n",
      " [ -548. -1289.]\n",
      " [ 2943.  -619.]\n",
      " [-2779.  2797.]\n",
      " [-3719. -2032.]]\n"
     ]
    }
   ],
   "source": [
    "im_path = '/media/topo/Data/ALS/Vallet/Images/18704.jpg'\n",
    "out_path = '/media/topo/Data/ALS/Vallet/Images/'\n",
    "\n",
    "#Load image \n",
    "img = cv2.imread(im_path)\n",
    "\n",
    "#Load raw measurements :\n",
    "xy = np.loadtxt(out_path + 'coord.txt', delimiter=' ')\n",
    "print(f\"Loaded {xy.shape[0]} measurements :\")\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define camera distorsion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the simplified Contrady-Brown distorsion model. \n",
    "This model relates distorded image coordinates $x_d, y_d$ (the points you just measured), to the undistorded ones $x, y$ through radial coefs ($k_1, k_2$) and tangential coefs ($p_1, p_2$) :\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "x(1 + k_1\\cdot r² + k_2 \\cdot r⁴) + p_1(r² + 2\\cdot x²) + 2\\cdot p_2\\cdot x\\cdot y - x_d = 0\n",
    "\\tag{1}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "y(1 + k_1\\cdot r² + k_2\\cdot r⁴) + p_2(r² + 2\\cdot y²) + 2\\cdot p_1\\cdot x\\cdot y - y_d = 0\n",
    "\\tag{2}\n",
    "\\end{equation*}\n",
    "\n",
    "With $r² = x² + y²$      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "$x, y, x_d, x_y$ are expressed in meters in the model.    \n",
    "You will need to convert from unit of pixel to meters for your measurements given the physical size of pixels of the camera : \n",
    "    \n",
    "$px_{cam} = 5.2e^{-6} [m]$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Define model\n",
    "\n",
    "We will use scipy non-linear solver to find for any measurment on the distorded image ($x_d, y_d$) the corresponding undistorded measurement ($x, y$).\n",
    "\n",
    "Define **undisort** function, which returns the two symbolic equations (1) and (2), given model's parameters, and undistorded coordinate of a measurement\n",
    "\n",
    "Have a look at scipy.optimize.fsolve function to understand its requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(var,x_d,y_d,k1,k2,p1,p2,px_size):  \n",
    "    '''\n",
    "    Define equation (1) and (2) given a complet set of parameter and distorded measurement coordinates\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var : tupple\n",
    "        tupple containing x and y variables. This are the two variables scipy solver will solve for\n",
    "        \n",
    "    x_d, y_d : floats\n",
    "        the coordinates of a measurment on the distorded image\n",
    "        \n",
    "    k1, k2, p1, p2 : floats\n",
    "        Contrady-Brown distorsion model coefficient\n",
    "    px_size : float\n",
    "        physical size of a pixel on the sensor [m]\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    list of size 2 containing both eqation of the Contrady-Brown model\n",
    "    '''\n",
    "    #Unpack variables\n",
    "    x, y = var\n",
    "    \n",
    "    #Convert x, y from pixels to meters to match distorsion model unit\n",
    "    x = x*px_size\n",
    "    y = y*px_size\n",
    "    x_d = x_d*px_size\n",
    "    y_d = y_d*px_size\n",
    "    \n",
    "    r2 = x*x + y*y\n",
    "\n",
    "    return [x*(1 + k1*r2 + k2*r2*r2) + p1*(r2+2*x*x) + 2*p2*x*y - x_d,\n",
    "            y*(1 + k1*r2 + k2*r2*r2) + p2*(r2+2*y*y) + 2*p1*x*y - y_d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Not sure where to pu the conversion from pixel unit to meter. If we keep px all along, coef of the distorsion model\n",
    "become super small (k2 -> 1e-20). Anyway I am not sure how to relate that with a distorsion model from metashape (whixh uses X/Z and Y/Z for x,y to with this manual implementation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Define function to generate coordinate grid and to plot distorsion correction results :\n",
    "\n",
    "We would now like to visualize on the image the distorsion model given the distorsion coefficients. \n",
    "\n",
    "To do so you can define a regular grid of pixels on the image and evaluate the distorsion model at each positions. You can the use the function **plot_distorsions** to visualize and optionnaly amplify the distorsion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_points(img, k):\n",
    "    '''\n",
    "    Generates a regular grid of points from an image (perspective centered frame)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : cv2.image\n",
    "        the image from which take a grid\n",
    "    k : int\n",
    "        the grid spacing in pixel\n",
    "            \n",
    "    Return\n",
    "    ------\n",
    "    grid : Nx2 np.array\n",
    "        the array of the grid, each line contains x,y coordinate of a given node\n",
    "    '''\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    x, y = np.meshgrid(np.arange(-width//2,width//2, k),\n",
    "                       np.arange(-height//2,height//2, k))\n",
    "    return np.array([x.flatten(), y.flatten()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distorsions(img, raw_pts, undist_pts, color=(0,0,255), thickness=3):\n",
    "    '''\n",
    "    Plots distortion vector on an imga given raw points and the undistorded equivalents\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : cv2.image\n",
    "        the image to plot\n",
    "        \n",
    "    raw_pts : np.array (Nx2)\n",
    "        the original grid without distortion correction\n",
    "        \n",
    "    undist_pts : np.array(Nx2)\n",
    "        the grid with distortion correction\n",
    "\n",
    "    '''\n",
    "    for i in range(len(raw_pts)):\n",
    "        cv2.line(img,\n",
    "                 (raw_pts[i]).astype(int),\n",
    "                 (undist_pts[i]).astype(int),\n",
    "                 color, thickness)\n",
    "        cv2.circle(img,\n",
    "                  (raw_pts[i].astype(int))\n",
    "                   , 2*thickness, color, -1)\n",
    "    \n",
    "    cv2.namedWindow('Distorsion Plot', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Distorsion Plot', img)\n",
    "    cv2.resizeWindow('Distorsion Plot', 1200,800)\n",
    "\n",
    "    while True:\n",
    "        k = cv2.waitKey(100)\n",
    "        if k == 27: # wait for ESC key to exit\n",
    "            cv2.destroyAllWindows()\n",
    "            break        \n",
    "        if cv2.getWindowProperty('Distorsion Plot',cv2.WND_PROP_VISIBLE) < 1:# wait for window to be closed        \n",
    "            break        \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Generate the grid, estimate undistorded coordinates from the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the grid with one point and project into perspective centered coordinates\n",
    "grid = grid_points(img,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define distorsion coefficients : \n",
    "# Radial coefficients\n",
    "k1 = 1\n",
    "k2 = 1\n",
    "# Tangential coefficients\n",
    "p1 = 1\n",
    "p2 = 1\n",
    "# pixel size\n",
    "px_size = 5.2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply distorsion model to the grid\n",
    "undistorded_grid = []\n",
    "for var in grid:\n",
    "    undistorded_grid.append(fsolve(undistort,\n",
    "                                   var,\n",
    "                                   args=(var[0], var[1],k1,k2,p1,p2,px_size)))\n",
    "    \n",
    "undistorded_grid = np.asarray(undistorded_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Visualize the result of the undistorded coordinates estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project both grids to sensor centered coordinates and visualize the results\n",
    "grid_p = perspective2sensor(img,grid)\n",
    "undistorded_grid_p = perspective2sensor(img,undistorded_grid)\n",
    "\n",
    "#Load image & plot\n",
    "img = cv2.imread(im_path)\n",
    "plot_distorsions(img, grid_p, undistorded_grid_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Apply camera distorsion model to manual measurements\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Load measurements and estimate undistorded coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "undist_xy = []\n",
    "for var in xy:\n",
    "    undist_xy.append(fsolve(undistort,\n",
    "                                   var,\n",
    "                                   args=(var[0], var[1],k1,k2,p1,p2,px_size)))\n",
    "undist_xy = np.asarray(undist_xy)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define distorsion coefficients : \n",
    "# Radial coefficients\n",
    "k1 = 1\n",
    "k2 = 1\n",
    "# Tangential coefficients\n",
    "p1 = 1\n",
    "p2 = 1\n",
    "# pixel size\n",
    "px_size = 5.2e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Project distorded and undistorded measurements to sensor centered frame and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_p = perspective2sensor(img, xy)\n",
    "undist_xy_p = perspective2sensor(img, undist_xy)\n",
    "\n",
    "#Load image \n",
    "img = cv2.imread(im_path)\n",
    "\n",
    "plot_distorsions(img, xy_p, undist_xy_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(out_path + 'coord_undistord.txt', undist_xy_p, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4453615cd91750b42a92082c1d2e45800de486616e18c6f6e61d58c8451ca01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
